{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "IrmA3eaj3kF0"
   },
   "outputs": [],
   "source": [
    "faqs = \"\"\"Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems, as opposed to the natural intelligence of living beings. It is a field of research in computer science that develops and studies methods and software which enable machines to perceive their environment and uses learning and intelligence to take actions that maximize their chances of achieving defined goals.[1] Such machines may be called AIs.\n",
    "\n",
    "AI technology is widely used throughout industry, government, and science. Some high-profile applications include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go).[2] However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[3][4]\n",
    "\n",
    "Alan Turing was the first person to conduct substantial research in the field that he called machine intelligence.[5] Artificial intelligence was founded as an academic discipline in 1956.[6] The field went through multiple cycles of optimism,[7][8] followed by periods of disappointment and loss of funding, known as AI winter.[9][10] Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques,[11] and after 2017 with the transformer architecture.[12] This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.[13]\n",
    "\n",
    "The growing use of artificial intelligence in the 21st century is influencing a societal and economic shift towards increased automation, data-driven decision-making, and the integration of AI systems into various economic sectors and areas of life, impacting job markets, healthcare, government, industry, and education. This raises questions about the long-term effects, ethical implications, and risks of AI, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
    "\n",
    "The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field's long-term goals.[14]\n",
    "\n",
    "To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[15]\n",
    "\n",
    "Goals\n",
    "The general problem of simulating (or creating) intelligence has been broken into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\n",
    "\n",
    "Reasoning and problem solving\n",
    "Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[16] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[17]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "J1D42emD32Ro"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "KhtDxwL_AXFj"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "K8MRFre9AaG9"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrpAl3EDAgvh",
    "outputId": "cabe3c83-7274-4512-94d5-b5def2b72453"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "44VahqKdAjr9"
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "  for i in range(1,len(tokenized_sentence)):\n",
    "    input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "CrzbvUUQCXPU"
   },
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "9oPMoWBSD1_U"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miRb-QZyIi7_",
    "outputId": "de5c2b4e-b6e6-4e4b-a892-f97eff72c1c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  13,   5],\n",
       "       [  0,   0,   0, ...,  13,   5,   4],\n",
       "       [  0,   0,   0, ...,   5,   4,   7],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 333, 334,   1],\n",
       "       [  0,   0,   0, ..., 334,   1,  71],\n",
       "       [  0,   0,   0, ...,   1,  71, 335]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "qVI0-UUrIsd3"
   },
   "outputs": [],
   "source": [
    "X = padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "lXrYHTDFI3uE"
   },
   "outputs": [],
   "source": [
    "y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmsFnHx1Qdow",
    "outputId": "38cc3392-f099-49e2-f0c9-52955380d43e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559, 111)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wyYqYgZSeck",
    "outputId": "5c223cc0-a8e9-4c4f-a364-a436bc492abf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "rs1NPitwSgzk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y,num_classes=336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQMJ0I6xSiZf",
    "outputId": "bba7b827-0696-427e-9d3d-c811600ce5a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559, 336)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "9kVeTvR2S8Fk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "wo-OYfHpTK2o"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(336, 100, input_length=111))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(336, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "-GGjqh7ue_Yq"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxxXkrSXfIBv",
    "outputId": "d809aa2b-600f-4549-cfc1-1dfd1fef1a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 111, 100)          33600     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 150)               150600    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 336)               50736     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 234936 (917.72 KB)\n",
      "Trainable params: 234936 (917.72 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpFUCALCfJRR",
    "outputId": "96d67a78-3c2e-4462-b2a8-2655c303af8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\nishu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nishu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "18/18 [==============================] - 14s 174ms/step - loss: 5.8095 - accuracy: 0.0519\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 5.6349 - accuracy: 0.0608\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 5.4475 - accuracy: 0.0608\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 5.4038 - accuracy: 0.0608\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 5.3887 - accuracy: 0.0608\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 3s 166ms/step - loss: 5.3708 - accuracy: 0.0608\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 5.3334 - accuracy: 0.0680\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 5.2611 - accuracy: 0.0716\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 3s 166ms/step - loss: 5.1672 - accuracy: 0.0733\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 5.0569 - accuracy: 0.0859\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 4.9138 - accuracy: 0.1002\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 4.7519 - accuracy: 0.1091\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 3s 166ms/step - loss: 4.5926 - accuracy: 0.1163\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 4.4072 - accuracy: 0.1234\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 4.2123 - accuracy: 0.1395\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 4.0226 - accuracy: 0.1377\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 3.8242 - accuracy: 0.1610\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 3.6067 - accuracy: 0.1699\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 3.4021 - accuracy: 0.2075\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 3.2106 - accuracy: 0.2522\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 3.0281 - accuracy: 0.2844\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 2.8339 - accuracy: 0.3256\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 2.6757 - accuracy: 0.3470\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 3s 177ms/step - loss: 2.4987 - accuracy: 0.4150\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 2.3514 - accuracy: 0.4687\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 2.2065 - accuracy: 0.5081\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 3s 166ms/step - loss: 2.0703 - accuracy: 0.5492\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 1.9374 - accuracy: 0.6100\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 3s 166ms/step - loss: 1.8216 - accuracy: 0.6691\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 1.7057 - accuracy: 0.7066\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 1.6050 - accuracy: 0.7460\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 1.5037 - accuracy: 0.7800\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 1.4105 - accuracy: 0.8175\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 3s 166ms/step - loss: 1.3243 - accuracy: 0.8301\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 1.2460 - accuracy: 0.8587\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 1.1705 - accuracy: 0.8730\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 1.1036 - accuracy: 0.9088\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 3s 175ms/step - loss: 1.0345 - accuracy: 0.9106\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 0.9772 - accuracy: 0.9356\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 0.9191 - accuracy: 0.9499\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 0.8577 - accuracy: 0.9714\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 0.8049 - accuracy: 0.9678\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 0.7627 - accuracy: 0.9750\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 4s 195ms/step - loss: 0.7138 - accuracy: 0.9767\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 0.6783 - accuracy: 0.9821\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 0.6403 - accuracy: 0.9875\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 0.6008 - accuracy: 0.9875\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 0.5669 - accuracy: 0.9911\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 0.5343 - accuracy: 0.9964\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 0.5080 - accuracy: 0.9928\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 3s 173ms/step - loss: 0.4772 - accuracy: 0.9946\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 4s 203ms/step - loss: 0.4529 - accuracy: 0.9964\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.4296 - accuracy: 0.9946\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 3s 172ms/step - loss: 0.4086 - accuracy: 0.9964\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 4s 203ms/step - loss: 0.3855 - accuracy: 0.9946\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 3s 170ms/step - loss: 0.3634 - accuracy: 0.9946\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.3457 - accuracy: 0.9946\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.3281 - accuracy: 0.9964\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 3s 170ms/step - loss: 0.3149 - accuracy: 0.9946\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 0.2983 - accuracy: 0.9946\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 0.2829 - accuracy: 0.9946\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2697 - accuracy: 0.9946\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.2562 - accuracy: 0.9946\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 3s 177ms/step - loss: 0.2450 - accuracy: 0.9946\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 4s 222ms/step - loss: 0.2330 - accuracy: 0.9946\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 4s 192ms/step - loss: 0.2234 - accuracy: 0.9946\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 4s 234ms/step - loss: 0.2144 - accuracy: 0.9946\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 4s 195ms/step - loss: 0.2046 - accuracy: 0.9946\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 0.1957 - accuracy: 0.9964\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1878 - accuracy: 0.9964\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 3s 173ms/step - loss: 0.1799 - accuracy: 0.9964\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 3s 177ms/step - loss: 0.1740 - accuracy: 0.9946\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.1670 - accuracy: 0.9964\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 4s 197ms/step - loss: 0.1604 - accuracy: 0.9946\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 3s 175ms/step - loss: 0.1547 - accuracy: 0.9946\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 3s 173ms/step - loss: 0.1483 - accuracy: 0.9946\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 4s 199ms/step - loss: 0.1427 - accuracy: 0.9946\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 4s 206ms/step - loss: 0.1381 - accuracy: 0.9946\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 3s 195ms/step - loss: 0.1334 - accuracy: 0.9964\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 4s 205ms/step - loss: 0.1289 - accuracy: 0.9946\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 4s 214ms/step - loss: 0.1243 - accuracy: 0.9946\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 4s 220ms/step - loss: 0.1199 - accuracy: 0.9946\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 5s 265ms/step - loss: 0.1166 - accuracy: 0.9946\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 3s 173ms/step - loss: 0.1120 - accuracy: 0.9964\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 0.1092 - accuracy: 0.9946\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 0.1058 - accuracy: 0.9964\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 0.1029 - accuracy: 0.9946\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 0.1000 - accuracy: 0.9946\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 0.0965 - accuracy: 0.9946\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.0941 - accuracy: 0.9964\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 3s 172ms/step - loss: 0.0910 - accuracy: 0.9946\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.0883 - accuracy: 0.9946\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.0863 - accuracy: 0.9964\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.0837 - accuracy: 0.9982\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 4s 198ms/step - loss: 0.0821 - accuracy: 0.9964\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 4s 208ms/step - loss: 0.0799 - accuracy: 0.9946\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.0779 - accuracy: 0.9946\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 4s 199ms/step - loss: 0.0760 - accuracy: 0.9946\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.0739 - accuracy: 0.9946\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 4s 212ms/step - loss: 0.0720 - accuracy: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ee991890d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGeYGwCMfTus",
    "outputId": "2d508555-b83e-470e-e7e5-1b5c10cce70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "artificial intelligence in the 21st century is\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "artificial intelligence in the 21st century is influencing\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "artificial intelligence in the 21st century is influencing a\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "artificial intelligence in the 21st century is influencing a societal\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "artificial intelligence in the 21st century is influencing a societal and\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "artificial intelligence in the 21st century is influencing a societal and economic\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "artificial intelligence in the 21st century is influencing a societal and economic shift\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "artificial intelligence in the 21st century is influencing a societal and economic shift towards\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "artificial intelligence in the 21st century is influencing a societal and economic shift towards increased\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "artificial intelligence in the 21st century is influencing a societal and economic shift towards increased automation\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = \"artificial intelligence in the 21st century\"\n",
    "\n",
    "for i in range(10):\n",
    "  # tokenize\n",
    "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  # padding\n",
    "  padded_token_text = pad_sequences([token_text], maxlen=111, padding='pre')\n",
    "  # predict\n",
    "  pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "  for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "      text = text + \" \" + word\n",
    "      print(text)\n",
    "      time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
